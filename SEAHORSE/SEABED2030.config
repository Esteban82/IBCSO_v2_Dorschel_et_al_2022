#!/usr/bin/bash
#this is the global config file that should ideally store all the relevant info in one place
umask u=rwx,g=rwx,o=

### GENERAL PARAMETERS
#---BASH FONT FORMAT
export NC='\e[0m' #no colour
export BOLD='\e[1m'
export DIM='\e[2m'
export UNDERLINE='\e[4m'
export RED='\e[1;31m' #bold Red console colour...
export GREEN='\e[1;32m' #bold Green console colour...
export BLUE='\e[1;34m' #bold Blue console colour...
export YELLOW='\e[1;33m' #bold Yellow console colour...
export WHITE='\e[1;97m' #bold White console colour...
export CYAN='\e[1;36m' #bold Cyan console colour...
export COL_WARNING=${RED}
export COL_IMPORTANT=${YELLOW}
export COL_INFO=${WHITE}
export COL_SUCCESS=${GREEN}

#---ALIASES
shopt -s expand_aliases
alias mkdir='mkdir -m770 -p'
alias rsync='rsync -a --omit-dir-times --delete'

#---MODULE DEFAULTS
export GMT="GMT/6.1.1 centoslibs/7.5"
export GDAL="gdal/2.3.2 centoslibs/7.5"
export NCO="nco/4.7.7 centoslibs/7.5" # netCDF utility module
export CONDA="miniconda/4.7.12"
export CONDA_ENV="~/envs/seabed2030"
export CONDA_ENV_DEV="~/envs/seabed2030_dev"

#---PROJECT VARS
export CURRENT_DATE=$(date +'%Y-%m-%d')
export CURRENT_DATE_TIME=$(date +'%Y-%m-%d %H:%M:%S') #this should be getDATETIME
export CURRENT_YEAR=$(date +'%Y')
export IBCSO_PROJ4="+proj=stere +ellps=WGS84 +lat_0=-90 +lon_0=0dE +lat_ts=-65" #proj4 string used for seabed data
export IBCSO_WKT="PROJCRS[\"WGS 84 / IBCSO Polar Stereographic\",BASEGEOGCRS[\"WGS 84\",DATUM[\"World Geodetic System 1984\",ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"IBCSO Polar Stereographic\",METHOD[\"Polar Stereographic (variant B)\",ID[\"EPSG\",9829]],PARAMETER[\"Latitude of standard parallel\",-65,ANGLEUNIT[\"degree\",0.0174532925199433]],PARAMETER[\"Longitude of origin\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],PARAMETER[\"False easting\",0,LENGTHUNIT[\"metre\",1]],PARAMETER[\"False northing\",0,LENGTHUNIT[\"metre\",1]],ID[\"EPSG\",9353]],CS[Cartesian,2],AXIS[\"easting (X)\",north,ORDER[1],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],AXIS[\"northing (Y)\",north,ORDER[2],LENGTHUNIT[\"metre\",1,ID[\"EPSG\",9001]]],USAGE[SCOPE[\"Hydrography and nautical charting.\"],AREA[\"Southern hemisphere - south of 50 deg S onshore and offshore, including Antarctica.\"],BBOX[-90,-180,-50,180]],ID[\"EPSG\",9354]]"
export IBCSO_EPSG=9354

export EVOKER=$(whoami) #whoever runs this script is the evoker (aka user)
export MAIL_EVOKER=${EVOKER}@awi.de
export MAIL_PROJECT_COORDINATOR="anonymous@domain" #project coordinator
export MAIL_PROJECT_DEV="developer1@domain,developer2@domain" #developer mail address(es)
export MAIL_ALL="all@domain" #all recipients
export MAIL_DEFAULTMSG="BEGIN,FAIL,END" #receive BEGIN messages, FAIL and END messages
export MAIL_ERROR_EXIT="FAIL,TIME_LIMIT,INVALID_DEPEND" #send mail in case of sbatch FAIL, TIME_LIMIT exceeds or INVALID_DEPEND

### DIRECTORY STRUCTURE
#--- BASIC FOLDER
export PROJECTDIR=~/project_folder #this is where the project is rooted
export DOC_DIR=${PROJECTDIR}/DOCUMENTATION #this is where the project documentation is at
export PUB_DIR=${PROJECTDIR}/PUBLICATION #this is where the official products rests
export END_USER_PRODUCT=${PUB_DIR}/CURRENT_PRODUCT # folder for zip files of products
export END_USER_COVERAGE=${END_USER_PRODUCT}/COVERAGE # folder for coverage geopackages
export END_USER_INTERNAL=${END_USER_PRODUCT}/INTERNAL_USE_RASTER # folder for coverage geopackages
export BASEDIR=${PROJECTDIR}/SEAHORSE #this is where the workflow is rooted
export SSD_DIR=/tmp #for fast I/O use the ssd mounted at /tmp on compute nodes
export ISIBHV_LOGDIR=${BASEDIR}/LOGS #this is where the condensed logs from work will be stored
export DATADIR=${BASEDIR}/DATA
export STATIC_DATADIR=${DATADIR}/STATIC
export COVERAGE_DIR=${TOOLDIR}/COVERAGE

#---SCRIPT FOLDER STRUCTURE
export SCRIPTDIR=${BASEDIR}/SCRIPTS #where all the scripts are
export SCRIPTDATADIR=${SCRIPTDIR}/DATA #where all the scripts are
export PYDIR=${SCRIPTDIR}/PYTHON #where all the py scripts are
export PYGENERALDIR=${PYDIR}/GENERAL #where all the general py scripts are
export SRUNDIR=${SCRIPTDIR}/SRUNS #where all the SRUNS scripts are
export TOOLDIR=${SCRIPTDIR}/TOOLS


#---ollie0/work folders
export WORKDIR=~/project_temp_folder #this is the partition / folder for intermediate / temp data
export WORK_TILEEXTENT_FILE=${WORKDIR}/tile_extents.txt #hard-coded tile-extents
export WORK_TILE_TABLE=${WORKDIR}/tiles_list.txt #file containing the metadata for augmenting the blockmedian files
export WORK_BASIC_TILE_TABLE=${WORKDIR}/basic_tiles_list.txt #file containing the metadata for augmenting the blockmedian files
export WORK_RID_TABLE=${WORKDIR}/RID_codes_augmentation.txt #file containing the metadata for augmenting the blockmedian files
export WORK_REMOVED=${WORKDIR}/REMOVED #folder containing the lines removed during B2
export WORK_EXTENT=${WORKDIR}/EXTENT #folder containing the extent created during B2
export WORK_MINMAX=${WORKDIR}/MINMAX #folder containing the minmax created during B2
export WORK_LISTUNIQUETILES=${WORKDIR}/LIST_UNIQUE_TILES #folder containing the *.uniquetiles created during B2 (list of unique tile IDs)
export WORK_PYDIR=${WORKDIR}/PYTHON #where all the py scripts are on work
export WORK_TILEDIR=${WORKDIR}/TILES #location of the tiled database on work/seabed2030
export WORK_SPLITXYZDIR=${WORKDIR}/SPLITDATA #location of the individual files; one file per SID with SID in the filename (!) and x,y,z
export WORK_BLOCKDIR=${WORKDIR}/BLOCKMEDIAN #location of the bm files;
export WORK_LARGEBLOCKDIR=${WORK_BLOCKDIR}/LARGE #location of the bm files;
export LOGBASEDIR=${WORKDIR}/LOGS #this is where all the logs will be stored

### FILE LOCATIONS
#---STATIC
export STATIC_BEDMACHINE_INTERP=${STATIC_DATADIR}/10 #file containing bedmachine interpolated data as xyz
export STATIC_BEDMACHINE_POINTS=${STATIC_DATADIR}/20 #file containing bedmachine measured data as xyz
export STATIC_VARIOUS_POINTS=${STATIC_DATADIR}/30 #file containing xyz from various sources (mainly topography)
export STATIC_MANUAL_POINTS=${STATIC_DATADIR}/40 #file containing manual data as xyz (both topography & bathymetry)
export STATIC_XYZ=${STATIC_DATADIR}/STATIC_XYZ.static #file containing steering points as xyz
export STATIC_XYZ_SURF=${STATIC_DATADIR}/STATIC_XYZ_SURF_BM.static #file containing steering points < upper limit ($SURF_UPPER_LIMIT)
export STATIC_RID=${STATIC_DATADIR}/STATIC_RID.static #file containing steering points rid
export STATIC_TID=${STATIC_DATADIR}/STATIC_TID.static #file containing steering points tid

# static files need to be in ${STATIC_DATADIR}
export STATIC_SRTM_GRID=${STATIC_DATADIR}/SRTM15_PS65.tif # SRTM15+ V2.2 grid (IBCSO projection, int16)
export STATIC_SRTM_SID=${STATIC_DATADIR}/SRTM15_SID_PS65.tif # SRTM15+ V2.2 SID grid (source identifier grid, IBCSO projection, int32)
export STATIC_SRTM_MASK=${STATIC_DATADIR}/SRTM15_mask.tif # SRTM15+ V2.2 mask of areas to INCLUDE during *D6* (1: use SRTM, 0: do NOT use) (IBCSO projection, int16)
export STATIC_BEDMACHINE_BED=${STATIC_DATADIR}/bedmachine_bed_PS65.tif # Bedmachine sub-ice topography (IBCSO projection, IBCSO extent, int16)
export STATIC_BEDMACHINE_ICESURFACE=${STATIC_DATADIR}/bedmachine_surface_PS65.tif # Bedmachine ice-surface (IBCSO projection, IBCSO extent, int16)
export STATIC_MASK_SOUTH_50_DEG=${STATIC_DATADIR}/IBCSO_mask_south_of_50deg.tif # mask of IBCSO v2 extent (south of 50Â°S)

export SEABED2030_CONFIG_FILE=${SCRIPTDIR}/SEABED2030.config
export PY_SYNC_SCRIPT=${PYGENERALDIR}/_GET_DYNAMIC_DATA.py # downloader for MySQL database tables (support points, metadata, tile definitions etc.)
export PY_QUERY_DB=${PYGENERALDIR}/_QUERY_DB.py # generic query for MySQL
export GDAL_SETBANDNAME_SCRIPT=${PYGENERALDIR}/gdal_set_band_names.py # small python wrapper to set band description from CLI
export STEERING_POINT_SCRIPT=${TOOLDIR}/PREPARE_STEERING_POINTS.sh # convert & harmonise steering points in DATA/STATIC
export ERROR_CHECK_SCRIPT=${TOOLDIR}/CHECKING_ERRORS.sh # script to check for both slurm and ollie errors
export CHAIN_SCRIPT=${SRUNDIR}/_CHAIN_template.srun # template chain script (with error check before execution of subsequent script)

#export PY_SEAHORSE_SUMMARY=${TOOLDIR}/DIVERSE/_create_SEAHORSE_summary_plots.py # create summary plots for SEAHORSE workflow
#export COVERAGE_SCRIPT=${COVERAGE_DIR}/COV1_cruise_coverages.sh # coverage generation script
#export HTML_SCRIPT_EXPORT=${TOOLDIR}/DIVERSE/SCRIPTS2HTML.sh
#export COVERAGE_GEOPACKAGE=$(find ${COVERAGE_DIR}/GEOMETRY/ -type f -name "*.gpkg") # wildcard needed because of timestamp in file name

#---DYNAMIC (FROM DATABASE BACKEND)
export TILEEXTENT_FILE=${SCRIPTDATADIR}/tile_extents.txt #hard-coded tile-extents
export RID_TABLE=${SCRIPTDATADIR}/RID_codes_augmentation.txt #file containing the metadata for augmening the blockmedian files
export METADATA_TABLE=${SCRIPTDATADIR}/metadata.txt #file containing the metadata
export METADATA_TABLE_WORKING=${SCRIPTDATADIR}/metadata_working.txt #file containing reduced metadata with fixed column order
export STEERING_POINTS_TABLE=${SCRIPTDATADIR}/steering_point_metadata.txt
export TILE_TABLE=${SCRIPTDATADIR}/tiles_list.txt #file containing the metadata for augmenting the blockmedian files
export BASIC_TILE_TABLE=${SCRIPTDATADIR}/basic_tiles_list.txt #file containing the metadata for augmening the blockmedian files


#----QA DATA FOLDER STRUCTURE
export QADIR=${BASEDIR}/QA #location of QA INFO
export QA_INC=${QADIR}/INCOMING #location of QA INFO
export QA_INC_NOT_IN_DB=${QA_INC}/NOT_IN_DB #files that are in incoming, but not in metadata
export QA_INC_INVALID=${QA_INC}/INVALID #location of QA INFO
export QA_INC_COMPLETED=${QA_INC}/COMPLETED #location of completed incoming cruises
export OLDDATADIR=${QADIR}/OLDDATA #location of the xyz files that were still on the server but are not registered on the db (from previous versions etc.)
export QA_TILE=${QADIR}/TILING
export QA_TILE_INVALID_DIR=${QA_TILE}/INVALID #location of QA INFO
export QA_EDIT_DIR=${QADIR}/EDITS
export QA_EDIT_TILES=${QA_EDIT_DIR}/TILES
export QA_EDIT_CRUISES=${QA_EDIT_DIR}/CRUISES
export QA_CHANGELOG=${QA_EDIT_DIR}/TRACE #where to store the deleted lines from editing?

#---INCOMING DATA FOLDER STRUCTURE
export INCOMINGDIR=${DATADIR}/INCOMING #location of the individual files
export INCOMINGSPLITDATADIR=${INCOMINGDIR}/SPLITDATA #location of the individual files; one file per SID with SID in the filename (!) and x,y,z

#---HARMONISED DATA FOLDER STRUCTURE
export XYZDIR=${DATADIR}/XYZ #location of the individual files; one file per SID with SID in the filename (!) and x,y,z

#---TILED DATA FOLDER STRUCTURE
export TILEDIR=${DATADIR}/TILES #location of the tiled database
export BASICTILEDIR=${TILEDIR}/BASIC #location of the aggregated, larger tiled database

#---BLOCKMEDIAN DATA FOLDER STRUCTURE
export BLOCKDIR=${DATADIR}/BLOCK_MEDIAN #location of blockmedian files (per tile)
export LARGEBLOCKDIR=${BLOCKDIR}/LARGE #location of large blockmedian files (aggregated basic tiles)

#---AUGMENTED DATA FOLDER STRUCTURE
export AUGDIR=${DATADIR}/AUGMENTED #location of blockmedian grids (aggregated tile)

#---PRODUCT DATA FOLDER STRUCTURE
export KEEP_RUNS=10 #how many product runs should be kept in $PRODUCTDIR
export PRODUCTDIR=${BASEDIR}/PRODUCT #location of all products

#ALL of the following are relative to the latest product folder
export RASTERPRODUCT="RASTER" #location of RASTER products (must be assigned in code, because versioning)
export GRIDPRODUCT="GRID" #location of RASTER products (must be assigned in code, because versioning)
export XYVPRODUCT="XYV" #location of RASTER products (must be assigned in code, because versioning)
export REPORTPRODUCT="REPORT" #location of RASTER products (must be assigned in code, because versioning)
export ZIPPRODUCT="ZIP" # folder for zip files of products

### DETAILED PARAMETERS
#----DATA SPLITTING
export CHUNK_XYZ_SIZE=1GB # new splitsize (for new tiling script)
export CHUNK_INCOMING_SIZE=300m #300MB #min max to good value because we expect less number of files
export HARM_LARGE_SIZE_LIMIT=2G
export SPLITSEPARATOR="#" #split character used to split large files

#----BLOCKMEDIAN SETTINGS
export BM_TINY_SIZE=10M
export BM_SMALL_SIZE=500M
export BM_REGION="-4800000/4800000/-4800000/4800000" #Block median region
export BM_SIZE="500" #Block median resolution
export AUGMENT_COL_NAMES=(x y rid min q25 median q75 max sum_weight data_name tid contrib_org dataset_weight) #column names of the augmented bm files

#----SURFACE SETTINGS
export SURF_RESO=500 #is this always the same as BM_SIZE? If so, then we could set it to BM_SIZE
export SURF_RESO_RAW=2000
export SURF_FILTER=6000 #Setting the width of the filter
export SURF_TENSION=0.35 #Settings for running 'surface'
export SURF_N_MAX_ITER=5000
export SURF_CONV_LIMIT=0.01
export SURF_L_LIMIT='u-0.1'
export SURF_UPPER_LIMIT=1420 #educated guess whatever jan says

#----RASTER SETTINGS
export RASTEROUTPUT_LIST_SMALL=( "rid" "tid" "mask" )   # keyword list for GeoTIFFs with Int16 as type!
export RASTEROUTPUT_TYPE_SMALL='-ot Int16 -a_nodata -32768'
export RASTEROUTPUT_TYPE='-ot Int32 -a_nodata -2147483648' # Int16 : -32768, Int32 : -2147483648
export RASTEROUTPUT_COMPRESSION='-co COMPRESS=DEFLATE -co PREDICTOR=2 -co ZLEVEL=6'
export RASTEROUTPUT_TILES='-co TILED=YES -co BLOCKXSIZE=4800 -co BLOCKYSIZE=4800'
export RASTEROUTPUT_FORMAT='-of GTiff'
export RASTEROUTPUT_RESO="500 500"
export RASTEROUTPUT_REGION_WGS84="-180.0 -90.0 180.0 -50.0"
export RASTEROUTPUT_RESO_WGS84="0.010647055359642483 0.010647055359642483" # in degree (from WKT), 500 m at 65Â°S: 0.010647055359642483 (ntbp: 0.0174532925199433)
export BENDING_SETTINGS='--buffer 3 --version smooth --percentage 0.2'
export GAP_FILL_SETTINGS='--blocksize_bm 10 --buffer 20 --version standard'
export SRTM_RID=500 # SRTM15+ RID value
export SRTM_TID=40 # SRTM15+ TID value

#----METADATA TAGS
export VAR_NAME="z"
export LONG_NAME="elevation"

export METATAG_NAME="International Bathymetric Chart of the Southern Ocean (IBCSO)"
export METATAG_VERSION="2.0"
export METATAG_DESCRIPTION="The International Bathymetric Chart of the Southern Ocean (IBCSO) v2 aims to represent the most comprehensive compilation of bathymetry for the Southern Ocean south of 50Â°S (https://www.scar.org/science/ibcso/ibcso/). IBCSO takes part in the Nippon Foundation â GEBCO Seabed 2030 project as the Regional Centre for the Southern Ocean (https://seabed2030.org/centers/southern-ocean-regional-center)."
export METATAG_INSTITUTION="Alfred Wegener Institute Helmholtz Centre for Polar and Marine Research (AWI)"
export METATAG_CONTACT="Dr. Boris Dorschel\nibcso@awi.de"
export METATAG_CONTACT_PERSON="Dr. Boris Dorschel"
export METATAG_CONTACT_EMAIL="ibcso@awi.de"
export METATAG_DOI=""
export METATAG_PARAMETER_NAME="elevation"
export METATAG_PARAMETER_UNIT="m"

export NC_METATAG_TITLE="International Bathymetric Chart of the Southern Ocean (IBCSO)"
export NC_METATAG_INSTITUTION="Alfred Wegener Institute Helmholtz Centre for Polar and Marine Research (AWI)"
export NC_METATAG_CONTACT="Dr. Boris Dorschel\nbathymetry@awi.de"
export NC_METATAG_COMMENT="The International Bathymetric Chart of the Southern Ocean (IBCSO) v2 aims to represent the most comprehensive compilation of bathymetry for the Southern Ocean south of 50Â°S (https://www.scar.org/science/ibcso/ibcso/). IBCSO takes part in the Nippon Foundation â GEBCO Seabed 2030 project as the Regional Centre for the Southern Ocean (https://seabed2030.org/centers/southern-ocean-regional-center)."
export NC_METATAG_DOI=""
export NC_METATAG_IBCSO_VERSION="2.0"



#----NEAREST NEIGHBOUR SETTINGS
export NN_NEIGHBOURS=4 
export NN_SEARCHRADIUS=1000
export NN_RESO=500

source ${SCRIPTDIR}/SEABED2030.functions

#POTENTIALLY UNNECCESARY
#export PYTHON="python3/3.7.7_intel2020u2" #this should be obsolete by now
#export NUMBEROFTILES=6700 #total number of possible tiles has 6535 tiles (but keep some extra) - is this still used?
#export NUMBEROFBASICTILES=600 #total number of basic tiles has 576 tiles - is this still used?
#export MAIL_DEFAULTUSER="seabed2k3k.awi.daemon@gmail.com" #send to this mail address
#export SRTM_GRID=${SCRIPTDATADIR}/STATIC/SRTM15_V2_IBCSO.tif
#export MASK_NO_SRTM=${SCRIPTDATADIR}/STATIC/mask_all_continental_shelf.tif
#export TILE_QA_TABLE=${SCRIPTDATADIR}/tile_QA.txt #table containing header and combination of qa and tile_info
#export AUGMENT_COL_KEEP=(1 2 3 4 5 6 7 8 9 10 11 12 13) #index of AUGMENT_COL_NAMES
#export SMALLBLOCKDIR=${BLOCKDIR}/SMALL #location of small blockmedian grids (per tile)
